{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "notebookfa05b003e9.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielsoy/AutoEncoder-SSIM-for-unsupervised-anomaly-detection-/blob/master/notebookfa05b003e9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "f2Lu04HQkxwv"
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "r429yWm4kxwz"
      },
      "source": [
        "# Convolution Neural Network\n",
        "# Src for dataset:\n",
        "# https://www.mvtec.com/company/research/datasets/mvtec-ad\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import roc_curve, auc, f1_score, roc_auc_score, precision_recall_curve,  \\\n",
        "    accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "import sys\n",
        "from distutils.dir_util import copy_tree\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "# Directory setup\n",
        "import os\n",
        "import sys\n",
        "nb_dir = os.path.split(os.getcwd())[0]\n",
        "if nb_dir not in sys.path:\n",
        "    sys.path.append(nb_dir)\n",
        "print(nb_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "hJsPkGi7kxw0"
      },
      "source": [
        "import os    \n",
        "os.environ['THEANO_FLAGS'] = \"device=gpu1\"  \n",
        "#import theano\n",
        "#theano.config.device = 'gpu'\n",
        "#theano.config.floatX = 'float32'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "vszoW5yTkxw0"
      },
      "source": [
        "ROOT_FOLDER_OF_TYPE = '../input/mvtec-ad-dataset/toothbrush'\n",
        "CASE_FOLDER = \"case_folder_2\"\n",
        "\n",
        "while os.path.exists(CASE_FOLDER):\n",
        "    CASE_FOLDER += \"_1\"\n",
        "\n",
        "if not os.path.exists(CASE_FOLDER):\n",
        "    os.makedirs(CASE_FOLDER)\n",
        "\n",
        "# Copy samples\n",
        "copy_tree(ROOT_FOLDER_OF_TYPE + '/train/good', CASE_FOLDER + '/test/good')\n",
        "copy_tree(ROOT_FOLDER_OF_TYPE + '/test/defective', CASE_FOLDER + '/test/defective')\n",
        "copy_tree(ROOT_FOLDER_OF_TYPE + '/test/good', CASE_FOLDER + '/train/good')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "i4_XeuTfkxw0"
      },
      "source": [
        "IMAGE_SIZE = 256\n",
        "\n",
        "train_batchsize = 20 #120\n",
        "val_batchsize = 4\n",
        "\n",
        "TRAIN_DIR = CASE_FOLDER + '/train'\n",
        "VALID_DIR = CASE_FOLDER + '/test'\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1/(255))\n",
        "validation_datagen = ImageDataGenerator(rescale = 1/(255))\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    TRAIN_DIR,\n",
        "    classes = ['defective', 'good'],\n",
        "    target_size= (IMAGE_SIZE, IMAGE_SIZE),  # All images will be resized to 512x512\n",
        "    batch_size= train_batchsize,\n",
        "    class_mode='binary')\n",
        "print(\"Train done...\")\n",
        "\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "    VALID_DIR,\n",
        "    classes = ['defective', 'good'],\n",
        "    target_size= (IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size= val_batchsize,\n",
        "    class_mode= 'binary',\n",
        "    shuffle= False)\n",
        "print(\"Vailidation done...\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "RV8TXkxckxw1"
      },
      "source": [
        "tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
        "tf.keras.layers.MaxPooling2D(2, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "j4pzcwvXkxw2"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    # Note the input shape is the desired size of the image 512x512 with 3 bytes color\n",
        "    # 1st convolution\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    # 2nd convolution\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # 3rd convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # 4th convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # 5th convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # Flatten the results to feed into a DNN\n",
        "    tf.keras.layers.Flatten(),\n",
        "    # 512 neuron hidden layer\n",
        "    tf.keras.layers.Dense(IMAGE_SIZE, activation='relu'),\n",
        "    # Only 1 output neuron. \n",
        "    # It will contain a value from 0-1 where 0 for 1 class ('dandelions') and 1 for the other ('grass')\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ORMU7zXbkxw2"
      },
      "source": [
        "#model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.RMSprop(lr=0.001), metrics=['accuracy'])\n",
        "# Changed to Adam optimizer and categorical corssentropy: gives ROC 62%, better than 56% though\n",
        "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Y9iRD4Xykxw3"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "jRFFDEN6kxw3"
      },
      "source": [
        "steps_per_epoch = train_generator.samples//train_generator.batch_size\n",
        "validation_steps = validation_generator.samples//validation_generator.batch_size\n",
        "print(\"Steps per epoch\", steps_per_epoch, \"Validation steps\", validation_steps)\n",
        "\n",
        "history = model.fit(train_generator, \n",
        "    steps_per_epoch=400,\n",
        "    epochs=15,\n",
        "    validation_data=validation_generator, \n",
        "    validation_steps=validation_steps,\n",
        "    verbose=1)\n",
        "\n",
        "model.evaluate(validation_generator)\n",
        "\n",
        "#STEP_SIZE_TEST=validation_generator.n//validation_generator.batch_size\n",
        "#validation_generator.reset()\n",
        "\n",
        "preds = model.predict(x=validation_generator, verbose=1)\n",
        "y_pred = preds.argmax(axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3j7dEVEvkxw4"
      },
      "source": [
        "fpr, tpr, _thresholds = roc_curve(validation_generator.classes, preds)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "print(\">>>> Confusion matrix\")\n",
        "print(confusion_matrix(validation_generator.classes, y_pred))\n",
        "\n",
        "print(\">>>> Accuracy %.2f\" % accuracy_score(validation_generator.classes, y_pred))\n",
        "print(\">>>> Precision %.2f\" % precision_score(validation_generator.classes, y_pred, average='macro'))\n",
        "print(\">>>> Recall %.2f\" % recall_score(validation_generator.classes, y_pred, average='macro'))\n",
        "print(\">>>> F1_score %.2f\" % f1_score(validation_generator.classes, y_pred, average='macro'))\n",
        "print('>>>> ROC AUC: %0.2f' % roc_auc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "ZNrpurF-kxw4"
      },
      "source": [
        "# Plot the ROC\n",
        "plt.figure()\n",
        "lw = 2\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic (ROC)')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()\n",
        "\n",
        "# Plot the Precision / Recall\n",
        "plt.figure()\n",
        "precision, recall, _ = precision_recall_curve(validation_generator.classes, preds)\n",
        "plt.plot(precision, recall)\n",
        "plt.xlabel('Precision')\n",
        "plt.ylabel('Recall')\n",
        "plt.title('Precision Recall Curve')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}